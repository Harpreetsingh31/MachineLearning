{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harpreet singh\\appdata\\local\\programs\\python\\python36-64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeledTrainData.csv\")\n",
    "test1 = pd.read_csv(\"testData.csv\")\n",
    "\n",
    "#Inputs and Output\n",
    "X = np.array(df['review'])\n",
    "y = np.array(df['sentiment'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .20,random_state = 42)\n",
    "\n",
    "#unlabeled dataset\n",
    "test  = np.array(test1['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data\n",
    "#Tokenzier\n",
    "num_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set:   This movie is just plain dumb.<br /><br />From the casting of Ralph Meeker as Mike Hammer to the fatuous climax, the film is an exercise in wooden predictability.<br /><br />Mike Hammer is one of detective fiction's true sociopaths. Unlike Marlow and Spade, who put pieces together to solve the mystery, Hammer breaks things apart to get to the truth. This film turns Hammer into a boob by surrounding him with bad guys who are ... well, too dumb to get away with anything. One is so poorly drawn that he succumbs to a popcorn attack.<br /><br />Other parts of the movie are right out of the Three Stooges play book. Velda's dance at the barre, for instance, or the bad guy who accidentally stabs his boss in the back. And the continuity breaks are shameful: Frau Blucher is running down the centerline of the road when the camera is tight on her lower legs but she's way over the side when the camera pulls back for a wider shot. The worst break, however, precedes the popcorn attack. The bad guy stalking Hammer passes a clock seconds after our hero, except the clock shows he was seven minutes behind our guy.<br /><br />To be fair, there were some interesting camera angles and lighting, and the grand finale is so bad that it must been seen, which is the only reason that it gets two points out of 10.\n",
      "Train-token-set:   [11, 17, 6, 40, 1041, 989, 7, 7, 36, 1, 973, 4, 3168, 14, 1946, 4225, 5, 1, 1326, 1, 19, 6, 32, 3453, 8, 1637, 8654, 7, 7, 1946, 4225, 6, 28, 4, 1252, 280, 1021, 2, 8373, 34, 273, 1323, 291, 5, 3318, 1, 732, 4225, 2027, 180, 969, 5, 76, 5, 1, 879, 11, 19, 502, 4225, 80, 3, 31, 3394, 87, 16, 75, 491, 34, 23, 70, 96, 989, 5, 76, 242, 16, 232, 28, 6, 35, 859, 1307, 12, 27, 5, 3, 3939, 1271, 7, 7, 82, 528, 4, 1, 17, 23, 205, 43, 4, 1, 288, 4656, 294, 271, 833, 30, 1, 15, 1821, 39, 1, 75, 229, 34, 2503, 8530, 24, 1422, 8, 1, 142, 2, 1, 2382, 2027, 23, 7849, 6, 617, 177, 1, 4, 1, 1314, 51, 1, 367, 6, 2694, 20, 38, 2368, 2976, 18, 437, 93, 117, 1, 496, 51, 1, 367, 2642, 142, 15, 3, 7065, 321, 1, 246, 986, 187, 1, 3939, 1271, 1, 75, 229, 6258, 4225, 4087, 3, 5493, 1571, 100, 261, 628, 546, 1, 5493, 284, 27, 13, 1545, 230, 493, 261, 229, 7, 7, 5, 26, 1250, 47, 68, 46, 218, 367, 2441, 2, 1518, 2, 1, 1754, 1958, 6, 35, 75, 12, 9, 212, 74, 107, 60, 6, 1, 61, 279, 12, 9, 211, 104, 754, 43, 4, 155]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-set:  \", (X_train[0]))\n",
    "print(\"Train-token-set:  \", (x_train_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding and Truncating Data¶\n",
    "#The Recurrent Neural Network can take sequences of arbitrary length as input\n",
    "\n",
    "#First we count the number of tokens in all the sequences in the data-set.\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.7972"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The average number of tokens in a sequence is:\n",
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The maximum number of tokens in a sequence is:\n",
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The max number of tokens we will allow is set to the average plus 2 standard deviations.\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94484"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This covers about 95% of the data-set.\n",
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 551)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padding or truncating the sequences that have a different length, \n",
    "#we need to determine if we want to do this padding or truncating 'pre' or 'post'\n",
    "pad = 'pre'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,padding=pad, truncating=pad)\n",
    "\n",
    "#We have now transformed the training-set into one big matrix of integers (tokens) with this shape:\n",
    "x_train_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 551)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The matrix for the test-set has the same shape:\n",
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11,   17,    6,   40, 1041,  989,    7,    7,   36,    1,  973,\n",
       "          4, 3168,   14, 1946, 4225,    5,    1, 1326,    1,   19,    6,\n",
       "         32, 3453,    8, 1637, 8654,    7,    7, 1946, 4225,    6,   28,\n",
       "          4, 1252,  280, 1021,    2, 8373,   34,  273, 1323,  291,    5,\n",
       "       3318,    1,  732, 4225, 2027,  180,  969,    5,   76,    5,    1,\n",
       "        879,   11,   19,  502, 4225,   80,    3,   31, 3394,   87,   16,\n",
       "         75,  491,   34,   23,   70,   96,  989,    5,   76,  242,   16,\n",
       "        232,   28,    6,   35,  859, 1307,   12,   27,    5,    3, 3939,\n",
       "       1271,    7,    7,   82,  528,    4,    1,   17,   23,  205,   43,\n",
       "          4,    1,  288, 4656,  294,  271,  833,   30,    1,   15, 1821,\n",
       "         39,    1,   75,  229,   34, 2503, 8530,   24, 1422,    8,    1,\n",
       "        142,    2,    1, 2382, 2027,   23, 7849,    6,  617,  177,    1,\n",
       "          4,    1, 1314,   51,    1,  367,    6, 2694,   20,   38, 2368,\n",
       "       2976,   18,  437,   93,  117,    1,  496,   51,    1,  367, 2642,\n",
       "        142,   15,    3, 7065,  321,    1,  246,  986,  187,    1, 3939,\n",
       "       1271,    1,   75,  229, 6258, 4225, 4087,    3, 5493, 1571,  100,\n",
       "        261,  628,  546,    1, 5493,  284,   27,   13, 1545,  230,  493,\n",
       "        261,  229,    7,    7,    5,   26, 1250,   47,   68,   46,  218,\n",
       "        367, 2441,    2, 1518,    2,    1, 1754, 1958,    6,   35,   75,\n",
       "         12,    9,  212,   74,  107,   60,    6,    1,   61,  279,   12,\n",
       "          9,  211,  104,  754,   43,    4,  155])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For example, we had the following sequence of tokens above:\n",
    "np.array(x_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,   11,   17,    6,   40, 1041,  989,\n",
       "          7,    7,   36,    1,  973,    4, 3168,   14, 1946, 4225,    5,\n",
       "          1, 1326,    1,   19,    6,   32, 3453,    8, 1637, 8654,    7,\n",
       "          7, 1946, 4225,    6,   28,    4, 1252,  280, 1021,    2, 8373,\n",
       "         34,  273, 1323,  291,    5, 3318,    1,  732, 4225, 2027,  180,\n",
       "        969,    5,   76,    5,    1,  879,   11,   19,  502, 4225,   80,\n",
       "          3,   31, 3394,   87,   16,   75,  491,   34,   23,   70,   96,\n",
       "        989,    5,   76,  242,   16,  232,   28,    6,   35,  859, 1307,\n",
       "         12,   27,    5,    3, 3939, 1271,    7,    7,   82,  528,    4,\n",
       "          1,   17,   23,  205,   43,    4,    1,  288, 4656,  294,  271,\n",
       "        833,   30,    1,   15, 1821,   39,    1,   75,  229,   34, 2503,\n",
       "       8530,   24, 1422,    8,    1,  142,    2,    1, 2382, 2027,   23,\n",
       "       7849,    6,  617,  177,    1,    4,    1, 1314,   51,    1,  367,\n",
       "          6, 2694,   20,   38, 2368, 2976,   18,  437,   93,  117,    1,\n",
       "        496,   51,    1,  367, 2642,  142,   15,    3, 7065,  321,    1,\n",
       "        246,  986,  187,    1, 3939, 1271,    1,   75,  229, 6258, 4225,\n",
       "       4087,    3, 5493, 1571,  100,  261,  628,  546,    1, 5493,  284,\n",
       "         27,   13, 1545,  230,  493,  261,  229,    7,    7,    5,   26,\n",
       "       1250,   47,   68,   46,  218,  367, 2441,    2, 1518,    2,    1,\n",
       "       1754, 1958,    6,   35,   75,   12,    9,  212,   74,  107,   60,\n",
       "          6,    1,   61,  279,   12,    9,  211,  104,  754,   43,    4,\n",
       "        155])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer Inverse Map\n",
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper-function for converting a list of tokens back to a string of words.\n",
    "def tokens_to_string(tokens):\n",
    "\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "\n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set:   This movie is just plain dumb.<br /><br />From the casting of Ralph Meeker as Mike Hammer to the fatuous climax, the film is an exercise in wooden predictability.<br /><br />Mike Hammer is one of detective fiction's true sociopaths. Unlike Marlow and Spade, who put pieces together to solve the mystery, Hammer breaks things apart to get to the truth. This film turns Hammer into a boob by surrounding him with bad guys who are ... well, too dumb to get away with anything. One is so poorly drawn that he succumbs to a popcorn attack.<br /><br />Other parts of the movie are right out of the Three Stooges play book. Velda's dance at the barre, for instance, or the bad guy who accidentally stabs his boss in the back. And the continuity breaks are shameful: Frau Blucher is running down the centerline of the road when the camera is tight on her lower legs but she's way over the side when the camera pulls back for a wider shot. The worst break, however, precedes the popcorn attack. The bad guy stalking Hammer passes a clock seconds after our hero, except the clock shows he was seven minutes behind our guy.<br /><br />To be fair, there were some interesting camera angles and lighting, and the grand finale is so bad that it must been seen, which is the only reason that it gets two points out of 10.\n",
      "Train-token-set:   this movie is just plain dumb br br from the casting of ralph as mike hammer to the climax the film is an exercise in wooden predictability br br mike hammer is one of detective true unlike and spade who put pieces together to solve the mystery hammer breaks things apart to get to the truth this film turns hammer into a by surrounding him with bad guys who are well too dumb to get away with anything one is so poorly drawn that he to a popcorn attack br br other parts of the movie are right out of the three stooges play book dance at the for instance or the bad guy who accidentally stabs his boss in the back and the continuity breaks are shameful is running down the of the road when the camera is tight on her lower legs but she's way over the side when the camera pulls back for a wider shot the worst break however the popcorn attack the bad guy stalking hammer passes a clock seconds after our hero except the clock shows he was seven minutes behind our guy br br to be fair there were some interesting camera angles and lighting and the grand finale is so bad that it must been seen which is the only reason that it gets two points out of 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-set:  \", (X_train[0]))\n",
    "print(\"Train-token-set:  \", (tokens_to_string(x_train_tokens[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\harpreet singh\\appdata\\local\\programs\\python\\python36-64\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py:1456: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#Create the Recurrent Neural Network¶\n",
    "\n",
    "model = Sequential()\n",
    "embedding_size = 8\n",
    "\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\harpreet singh\\appdata\\local\\programs\\python\\python36-64\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 551, 8)            80000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 16)          1200      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 8)           600       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 81,961\n",
      "Trainable params: 81,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "19000/19000 [==============================]19000/19000 [==============================] - 309s 16ms/step - loss: 0.6791 - acc: 0.5543 - val_loss: 0.6192 - val_acc: 0.6550\n",
      "\n",
      "Epoch 2/3\n",
      "19000/19000 [==============================]19000/19000 [==============================] - 357s 19ms/step - loss: 0.4961 - acc: 0.7618 - val_loss: 0.4211 - val_acc: 0.8080\n",
      "\n",
      "Epoch 3/3\n",
      "19000/19000 [==============================]19000/19000 [==============================] - 350s 18ms/step - loss: 0.3669 - acc: 0.8458 - val_loss: 0.4007 - val_acc: 0.8250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x2a990112748>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Recurrent Neural Network¶\n",
    "\n",
    "model.fit(x_train_pad, y_train,\n",
    "          validation_split=0.05, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================]5000/5000 [==============================] - 29s 6ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performance on Test-Set¶\n",
    "result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of Mis-Classified Text\n",
    "y_pred = model.predict(x=x_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n",
    "cls_true = np.array(y_test[0:1000])\n",
    "\n",
    "\n",
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = incorrect[0]\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The key to The 40-Year-Old Virgin is not merely that Andy Stitzer is a 40-year-old virgin, but rather the manner in which Steve Carell presents him as one. In a genre of crass \\\\comedy\\\\\" that has become typified by its lack of humor and engaging characters, The 40-Year-Old Virgin offers a colorful cast and an intelligent, heartfelt script that doesn\\'t use its protagonist as the butt-end of cruel jokes. That Andy is still a virgin at forty years old is not as much a joke, in fact, as it is a curiosity.<br /><br />Carell, a veteran of Team Ferrell in Anchorman and an ex-Daily Show castmember, uses the concept of the film to expand his character Â– we get to understand why Andy is the way he is. It\\'s the little things that make this film work. When Andy\\'s co-worker at an electronics store asks him what he did for the weekend, Andy describes his failed efforts at cooking. When Andy rides his bike to work, he signals his turns. He doesn\\'t just adorn his home with action figures Â– he paints them, and talks to them, and reveals that some of the really old ones have belonged to him since childhood. A lesser comedy wouldn\\'t even begin to focus on all of these things.<br /><br />The plot is fairly simplistic Â– Andy\\'s co-worker pals find out he\\'s never had sex and they make it a personal quest of theirs to get him in bed with a woman. It\\'s a childish idea and the film makes no attempt to conceal its juvenility.<br /><br />Andy\\'s friends are a complement to his neurotic nature: David (Paul Rudd) has broken up with his girlfriend over two years ago but is still obsessed with her, Jay (Romany Malco) is a womanizing ladies\\' man and Cal (Seth Rogen) is a tattooed sexaholic. Their attempts at getting Andy in the sack backfire numerous times, and each time leaves Andy feeling less and less optimistic.<br /><br />Finally Andy meets single mom Trish (played by Catherine Keener) and, much to the chagrin of his worrying buddies who claim mothers aren\\'t worth it, he falls in love with her. They begin a relationship and agree to put off having sex for twenty days Â– Trish being unaware that Andy is still a virgin.<br /><br />The 40-Year-Old Virgin was directed by Judd Apatow, the man who produced Anchorman and The Cable Guy, and began the short-lived cult TV show Freaks and Geeks. Apatow is renowned for his unique sense of humor, and the script Â– co-written by Carell Â– offers plenty.<br /><br />However, in the end the most interesting and (indeed surprising) aspect of The 40-Year-Old Virgin is its maturity. By now you are probably well aware that the film received glowing reviews from the critics, and even I was surprised by its warm reception. But after seeing the film, it\\'s easy to understand why. We like Andy. We care about him. He\\'s not just some cardboard cutout sex-comedy clichÃ© Â– he\\'s a real, living, breathing person. His neurotic traits combine the best of Woody Allen with childish naivety. His friends are not unlikable jerks and his romance is tumultuous and bittersweet. It strikes a chord with the audience.<br /><br />Although this is far from being a perfect movie and definitely contains some rather crude innuendo and sexual humor, it doesn\\'t offend to the extent that other genre entries might have because we have affection for the people on-screen. The best sex comedies work this way Â– from Risky Business to American Pie Â– and that is the major difference between something like The 40-Year-Old Virgin and 40 Days and 40 Nights.\"'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mis0classified text\n",
    "text = X_test[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27526477"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are the predicted and true classes for the text:\n",
    "y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_true[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 551)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets us try on new data\n",
    "tokens = tokenizer.texts_to_sequences(test)\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9407548 ],\n",
       "       [0.05553144],\n",
       "       [0.8264502 ],\n",
       "       ...,\n",
       "       [0.13183978],\n",
       "       [0.9346127 ],\n",
       "       [0.20734578]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
