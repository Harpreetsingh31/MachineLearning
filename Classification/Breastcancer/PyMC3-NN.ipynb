{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures,scale\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "import pymc3 as pm\n",
    "#import seaborn as sns; sns.set()\n",
    "from scipy import stats, optimize\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano import shared\n",
    "import theano.tensor as T\n",
    "from pymc3 import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "df = pd.read_csv('breast-cancer-wisconsin.csv')\n",
    "#df.dropna(how='any',inplace=True)\n",
    "\n",
    "df.drop(['id'],1,inplace=True)\n",
    "#df.replace('?',-99999,inplace=True)\n",
    "\n",
    "##IMP NOTE: I basically dropped 'bare_nuclei' bcuz of 16 \"?\" values\n",
    "X = scale(np.array(df.drop(['class','bare_nuclei'],1)))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "#Split Data\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "#Preprocess data for Modeling\n",
    "ann_input = shared(X_tr)\n",
    "ann_output = shared(y_tr)\n",
    "n_hidden = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_1 = np.random.randn(X.shape[1], n_hidden)\n",
    "init_2 = np.random.randn(n_hidden, n_hidden)\n",
    "init_out = np.random.randn(n_hidden)\n",
    "\n",
    "with pm.Model() as neural_network:\n",
    "    # Weights from input to hidden layer\n",
    "    weights_in_1 = pm.Normal('w_in_1', 0, sd=1,\n",
    "    shape=(X.shape[1], n_hidden),\n",
    "    testval=init_1)\n",
    "\n",
    "    # Weights from 1st to 2nd layer\n",
    "    weights_1_2 = pm.Normal('w_1_2', 0, sd=1,\n",
    "                        shape=(n_hidden, n_hidden),\n",
    "                        testval=init_2)\n",
    "\n",
    "    # Weights from hidden layer to output\n",
    "    weights_2_out = pm.Normal('w_2_out', 0, sd=1,\n",
    "                          shape=(n_hidden,),\n",
    "                          testval=init_out)\n",
    "\n",
    "    # Build neural-network\n",
    "    act_1 = T.tanh(T.dot(ann_input, weights_in_1))\n",
    "    act_2 = T.tanh(T.dot(act_1, weights_1_2))\n",
    "    act_out = T.nnet.sigmoid(T.dot(act_2, weights_2_out))\n",
    "\n",
    "    out = pm.Bernoulli('data',\n",
    "                   act_out,\n",
    "                   observed=ann_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = inf: 100%|██████████████████████████████████████████████████████████| 5000/5000 [07:58<00:00, 10.45it/s]\n",
      "Finished [100%]: Average Loss = nan\n"
     ]
    }
   ],
   "source": [
    "#infering parameters\n",
    "with neural_network:\n",
    "    inference=pm.ADVI()\n",
    "    approx = pm.fit(n=5000,more_replacements={\n",
    "        ann_input:pm.Minibatch(X_tr),\n",
    "        ann_output:pm.Minibatch(y_tr)\n",
    "    \n",
    "     }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Replace shared variables with testing set\n",
    "#(note that using this trick we could be streaming ADVI for big data)\n",
    "ann_input.set_value(X_te)\n",
    "ann_output.set_value(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 702.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0%\n"
     ]
    }
   ],
   "source": [
    "#Creater posterior predictive samples\n",
    "trace= approx.sample(draws=5000)\n",
    "ppc = pm.sample_ppc(trace, model=neural_network, samples=500)\n",
    "pred = ppc['data'].mean(axis=0) > 0.5\n",
    "\n",
    "print('Accuracy = {}%'.format((y_te == pred).mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
