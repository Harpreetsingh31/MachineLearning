{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harpreet singh\\appdata\\local\\programs\\python\\python36-64\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "df = pd.read_csv('breast-cancer-wisconsin.csv')\n",
    "df.replace('?',-99999,inplace=True)\n",
    "df.drop(['id'],1,inplace=True)\n",
    "\n",
    "X = np.array(df.drop(['class','bare_nuclei'],1))\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .20,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.957013 (0.018414)\n",
      "LDA: 0.949838 (0.016804)\n",
      "KNN: 0.949838 (0.021019)\n",
      "CART: 0.935551 (0.021621)\n",
      "NB: 0.956997 (0.015641)\n",
      "SVM: 0.958735 (0.018688)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr testing\n",
      "0.9714285714285714\n",
      "Coefficients: [[0.31242254 0.10996486 0.44464014 0.18344483 0.04387358 0.31652595\n",
      "  0.1017104  0.13944887]]\n",
      "Intercept: [-6.1653044]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on validation dataset\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "print(\"lr testing\")\n",
    "print(accuracy_score(y_test, predictions))\n",
    "#print(confusion_matrix(y_test, predictions))\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "coeff = lr.coef_\n",
    "inter = lr.intercept_\n",
    "\n",
    "print('Coefficients: {}'.format(coeff))\n",
    "print('Intercept: {}'.format(inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "559/559 [==============================] - 1s 2ms/step - loss: 0.7734 - acc: 0.6619\n",
      "Epoch 2/15\n",
      "559/559 [==============================] - 0s 322us/step - loss: 0.6619 - acc: 0.6494\n",
      "Epoch 3/15\n",
      "559/559 [==============================] - 0s 315us/step - loss: 0.6278 - acc: 0.6494\n",
      "Epoch 4/15\n",
      "559/559 [==============================] - 0s 293us/step - loss: 0.5893 - acc: 0.6494\n",
      "Epoch 5/15\n",
      "559/559 [==============================] - 0s 293us/step - loss: 0.5421 - acc: 0.6494\n",
      "Epoch 6/15\n",
      "559/559 [==============================] - 0s 308us/step - loss: 0.4967 - acc: 0.6583\n",
      "Epoch 7/15\n",
      "559/559 [==============================] - 0s 279us/step - loss: 0.4506 - acc: 0.8587\n",
      "Epoch 8/15\n",
      "559/559 [==============================] - 0s 279us/step - loss: 0.4115 - acc: 0.9016\n",
      "Epoch 9/15\n",
      "559/559 [==============================] - 0s 322us/step - loss: 0.3824 - acc: 0.9159\n",
      "Epoch 10/15\n",
      "559/559 [==============================] - 0s 343us/step - loss: 0.3564 - acc: 0.9159\n",
      "Epoch 11/15\n",
      "559/559 [==============================] - 0s 302us/step - loss: 0.3323 - acc: 0.9284\n",
      "Epoch 12/15\n",
      "559/559 [==============================] - 0s 315us/step - loss: 0.3107 - acc: 0.9284\n",
      "Epoch 13/15\n",
      "559/559 [==============================] - 0s 315us/step - loss: 0.2965 - acc: 0.9320\n",
      "Epoch 14/15\n",
      "559/559 [==============================] - 0s 315us/step - loss: 0.2778 - acc: 0.9267\n",
      "Epoch 15/15\n",
      "559/559 [==============================] - 0s 293us/step - loss: 0.2652 - acc: 0.9320\n",
      "140/140 [==============================] - 0s 314us/step\n",
      "Evaluation result on Test Data : Loss = 0.23308257226433074, accuracy = 0.9285714328289032\n"
     ]
    }
   ],
   "source": [
    "#Applying Neural network\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import scale\n",
    "y2 = pd.get_dummies(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y2,test_size = .20,random_state = 42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(X.shape[1], input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'rmsprop',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,nb_epoch= 15, verbose=1,batch_size=5)\n",
    "\n",
    "[test_loss, test_acc] = model.evaluate(X_test, y_test, batch_size=5)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
