import pymc3 as pmimport numpy as npimport pandas as pdimport matplotlib.pyplot as plt#import seaborn as sns; sns.set()from scipy import stats, optimizefrom sklearn.datasets import load_diabetesfrom sklearn.cross_validation import train_test_splitfrom theano import sharednp.random.seed(9)#Load the Datadiabetes_data = load_diabetes()X, y_ = diabetes_data.data, diabetes_data.target#Split DataX_tr, X_te, y_tr, y_te = train_test_split(X,y_,test_size=0.25, random_state=42)#Generate Modellinear_model = pm.Model()with linear_model:    # Priors for unknown model parameters        alpha = pm.Normal("alpha", mu=y_tr.mean(),sd=1)    betas = pm.Normal("betas", mu=0, sd=1, shape=X.shape[1])    sigma = pm.HalfNormal("sigma", sd=1) # you could also try with a HalfCauchy that has longer/fatter tails    # Expected value of outcome    mu = alpha + pm.math.dot(betas, X_tr.T)    # Likelihood (sampling distribution of observations)    likelihood = pm.Normal("likelihood", mu=mu, sd=sigma, observed=y_tr)    # Obtain starting values via Maximum A Posteriori Estimate    map_estimate = pm.find_MAP(model=linear_model, fmin=optimize.fmin_powell)    # Instantiate Sampler    step = pm.NUTS(scaling=map_estimate)    # MCMC    trace = pm.sample(1000, step, start=map_estimate, progressbar=True, njobs=1)    chain = trace[100:]pm.traceplot(chain);